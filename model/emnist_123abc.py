# -*- coding: utf-8 -*-
"""emnist_123ABC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16YtnpdiDW0F3mPOXmZigrvgZRMvL9wpf

## Download EMNIST dataset
"""

import keras
import tensorflow as tf
import numpy as np
import scipy.io
import matplotlib.pyplot as plt
import seaborn as sns
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint
from keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix
from keras.models import load_model


###############################################################################
# DATASET setup
###############################################################################

print("DATASET setup ....")


# this dataset containts digits ( 0-9 ) and letters ( A-Z and a-z )
# labels are (0-9) (10-35) (36-)
emnist = scipy.io.loadmat("emnist-balanced.mat")
x_train = emnist["dataset"][0][0][0][0][0][0].astype(np.float32)
y_train = emnist["dataset"][0][0][0][0][0][1]
x_test  = emnist["dataset"][0][0][1][0][0][0].astype(np.float32)
y_test  = emnist["dataset"][0][0][1][0][0][1]

# normalize data to 0.0 - 1.0 range
x_train /= 255.0
x_test /= 255.0

# reshape images and labes
x_train_ds = x_train.reshape(x_train.shape[0], 28, 28, 1, order="F")
x_test_ds  = x_test.reshape(x_test.shape[0], 28, 28, 1, order="F")
y_train_ds = y_train.reshape(y_train.shape[0])
y_test_ds  = y_test.reshape(y_test.shape[0])

# NUMBERS and CAPITAL LETTERS
x_train = x_train_ds[ np.nonzero(y_train_ds < 36) ]
y_train = y_train_ds[ np.nonzero(y_train_ds < 36) ]
x_test  = x_test_ds[ np.nonzero(y_test_ds < 36) ]
y_test  = y_test_ds[ np.nonzero(y_test_ds < 36) ]
NUM_CLASSES = 36

# ONLY NUMBERS
# x_train = x_train_ds[ np.nonzero(y_train_ds < 10) ]
# y_train = y_train_ds[ np.nonzero(y_train_ds < 10) ]
# x_test  = x_test_ds[ np.nonzero(y_test_ds < 10) ]
# y_test  = y_test_ds[ np.nonzero(y_test_ds < 10) ]
# NUM_CLASSES = 10

# ONLY CAPITAL LETTERS
# x_train = x_train_ds[ np.nonzero((y_train_ds < 36) * (y_train_ds > 9)) ]
# y_train = y_train_ds[ np.nonzero((y_train_ds < 36) * (y_train_ds > 9)) ] - 10
# x_test  = x_test_ds[ np.nonzero((y_test_ds < 36) * (y_test_ds > 9)) ]
# y_test  = y_test_ds[ np.nonzero((y_test_ds < 36) * (y_test_ds > 9)) ] - 10
# NUM_CLASSES = 26

for i in range(10):
  plt.subplot(2,5,i+1)
  plt.imshow(x_train[i].reshape((28,28)) , cmap='gray')
plt.show()

sns.countplot(y_train)
plt.show()

sns.countplot(y_test)
plt.show()





###############################################################################
# NETWORK training
###############################################################################


print("NETWORK training ...")

np.random.seed(2)
tf.set_random_seed(2)

INPUT_SHAPE = (28, 28, 1)
KERNEL_SIZE = (3,3)
RUN_ID = "model_EMNIST.h5"

conv_model = Sequential()
conv_model.add( Conv2D(3, kernel_size=KERNEL_SIZE, padding='same',activation='relu', input_shape=INPUT_SHAPE) )
conv_model.add( Conv2D(3, kernel_size=KERNEL_SIZE, padding='same',activation='relu') )
conv_model.add( Conv2D(3, kernel_size=KERNEL_SIZE, strides=(2, 2),padding='same') )
conv_model.add( Conv2D(12, kernel_size=KERNEL_SIZE, padding='same',activation='relu') )
conv_model.add( Conv2D(12, kernel_size=KERNEL_SIZE, padding='same',activation='relu') )
conv_model.add( Conv2D(12, kernel_size=KERNEL_SIZE, strides=(2, 2),padding='same') )
conv_model.add( Flatten() )
conv_model.add( Dense(64, activation='relu') )
conv_model.add( Dense(NUM_CLASSES, activation='softmax') )
conv_model.summary()
EPOCHS = 10
BATCH_SIZE = 1000

conv_model.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(), metrics=['accuracy'])
checkpointer = ModelCheckpoint(RUN_ID,verbose=1,save_best_only=True,monitor='val_acc')
training_history = conv_model.fit(x_train, y_train,batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=(x_test, y_test),callbacks=[checkpointer])

###############################################################################
# NETWORK evaluation
###############################################################################

# Commented out IPython magic to ensure Python compatibility.
import scipy.io
import numpy as np
import matplotlib.pyplot as plt
import itertools
from keras.models import load_model
from keras.optimizers import Adam
from sklearn.metrics import confusion_matrix

###############################################################################
#
# PLOTTING FACILITIES
#
###############################################################################

def plot_confusion_matrix(cm, classes,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    """
    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

nn = load_model(RUN_ID)
score = nn.evaluate(x_test,y_test)
print("Test accuracy (loss): {1:.3g} ({0:.3g})\n".format(*score))

predictions = nn.predict(x_test)
predicted_class = predictions.argmax(axis=-1)
conf_mat = confusion_matrix(y_test,predicted_class)
labels = []
for i in np.arange(48,58):
  labels.append(chr(i))
for i in np.arange(65,91):
  labels.append(chr(i))
#plt.figure(figsize=(14, 14), dpi=80)
plot_confusion_matrix(conf_mat,labels)
plt.show()